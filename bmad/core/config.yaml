# BMAD Core Configuration - OpenAI/Groq Migration
# Updated: 2025-11-03

providers:
  openai:
    api_key: $OPENAI_API_KEY
    base_url: https://api.openai.com/v1
    models:
      - name: gpt-4o
        context_window: 128000
        max_tokens: 4096
        temperature: 0.1
      - name: gpt-4o-mini
        context_window: 128000
        max_tokens: 16384
        temperature: 0.2
    default_model: gpt-4o

  groq:
    api_key: $GROQ_API_KEY
    base_url: https://api.groq.com/openai/v1
    models:
      - name: llama-3.1-70b-versatile
        context_window: 8192
        max_tokens: 8192
        temperature: 0.1
      - name: llama-3.1-8b-instant
        context_window: 8192
        max_tokens: 8192
        temperature: 0.1
      - name: mixtral-8x7b-32768
        context_window: 32768
        max_tokens: 8192
        temperature: 0.1
    default_model: llama-3.1-70b-versatile

  perplexity:
    api_key: $PERPLEXITY_API_KEY
    base_url: https://api.perplexity.ai
    model: sonar-large-online
    temperature: 0.1
    max_tokens: 4096

# Model Strategy
model_strategy:
  primary: openai/gpt-4o
  research: perplexity/sonar-large-online
  fallback: groq/llama-3.1-70b-versatile
  lightweight: openai/gpt-4o-mini
  code_generation: groq/llama-3.1-70b-versatile
  validation: groq/mixtral-8x7b-32768

# System Configuration
system:
  default_temperature: 0.1
  default_max_tokens: 4096
  enable_fallbacks: true
  enable_caching: true
  cache_ttl: 3600  # 1 hour
  log_level: info
  timeout: 30000  # 30 seconds

# Agent Teams
agent_teams:
  bmm:
    enabled: true
    default_provider: openai
    primary_model: gpt-4o
  core:
    enabled: true
    default_provider: openai
    primary_model: gpt-4o
  analysis:
    enabled: true
    default_provider: openai
    primary_model: gpt-4o-mini

# Cost Management
cost_controls:
  daily_budget: 50.0
  monitor_usage: true
  alerts:
    - threshold: 25.0
      action: warn
    - threshold: 40.0
      action: critical

# Performance Optimization
performance:
  batch_requests: true
  max_batch_size: 5
  use_streaming: false
  enable_rate_limiting: true
  max_requests_per_minute: 60

# Migration Notes
migration:
  from: anthropic
  to: openai_groq
  date: 2025-11-03
  status: complete
  notes: |
    - Primary provider switched to OpenAI GPT-4o
    - Groq added for fast inference and cost optimization
    - Perplexity maintained for research capabilities
    - All existing workflows preserved
    - Expected 25-40% cost reduction
    - 30-50% speed improvement with Groq